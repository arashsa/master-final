\chapter{Conclusion}
\label{chap:conclusion}

% Kort minne om motivasjon, problemstilling, og spørsmål. Mer om resultatene, litt mer i dybden. Outlook. 

In this thesis, we have presented an in-depth contrastive error analysis of a selected set of semantic dependency parsing systems that participated in SemEval-2015. The analysis of Chapter \ref{chap:analysis} pointed in the direction of semantic frame classification as an interesting case to pursue as its own task. This was due to our hypothesis that the results of previous work showed a possibility of improvement based on the accuracy observed on the 30 most frequent frames.

In Chapter \ref{chap:experiments} we presented the experimental setup for our classification task. We presented the data used for training, development and testing. We also presented the type of features that we would examine. We showed that our feature design would be based on lexical, morphological, syntactic and semantic features. 

The experiments that we ran in Chapter \ref{chap:results} where designed so that we could extensively test the features presented in Chapter \ref{chap:experiments}. We selected the best set of features in an additive manner; testing new features based on the previous set of features that we included. We also tested 4 different machine learning algorithms, and finally landed on Support Vector Machines for our classifier.

With the experimental setup in place we set out to create two distinct classifiers; one that would use syntactic features, and one that would use semantic dependencies as features. Both classifiers would share the same underlying lexical and morphological features. The classifier using semantic features would be used as a possible extension to the parsing systems examined in Chapter \ref{chap:analysis}.

With this in place we ran the classifier based on semantic features on the gold standard test data, and on the data produced by the Lisbon and Peking parsing system. The first run produced very accurate results, with a F-score of 93.91\% for DM and 86.80\% for PSD. Since we used gold standard semantic dependencies during classification, this can be considered an upper bound to the accuracy of our classifier. Using the semantic dependencies produced by Lisbon, we presented the Lisbon++ system, achieving a F-score of 86.96\% for DM and 84.74\% for PSD. The same run on Peking's, resulting in the Peking++ system, we achieved a F-score of 84.65\% for DM and 84.29\% for PSD. These scores proved to outperform previous results.

\section{Future Work}
\label{future_work}

% Would have liked to work more on this for another year.
% Train lisbon parser with information from our frame classification

There are several experiments that we could run in order to push the accuracy of our classifiers further. A step that the we would like to pursue further is to examine how \textit{Word Representations in Vector Space} might improve the accuracy of our classifier. Concatenating the vectors of approaches from \citeA{word2vec}: Word2Vec, and \citeA{glove}: Glove, with the feature vectors used for our training, would be an interesting approach. A more recent approach by \citeA{sense2vec}: Sence2Vec, which was used by the authors for word sense disambiguation, would be particularly interesting for feature enhancement.