\chapter{Background}
\label{chap:background}

This chapter provides an introduction to dependency grammar and reviews the state-of-the-art in dependency-based parsing. We start by exploring dependency grammar in order to provide the reader with an insight to the theoretical foundations of dependency parsing, and to formally define its properties. We examine two main approaches to dependency parsing: the grammar-driven and the data-driven. These two are not mutually exclusive, and as we shall see, there are approaches that are based on both. We then introduce syntactic and semantic dependency parsing. As a superficial starting point we can state that the dependency relations in the former are represented predominantly in the research community as a \textit{tree} data structure, while the latter are predominantly represented as a \textit{graph} data structure. This chapter formally describes these two approaches  to dependency parsing, gives an overview of their similarities and differences, and provides the reader with a basis for our work and analysis in the subsequent chapters. This chapter is not a comprehensive historical review, or an attempt at an in-depth formal description of dependency parsing. Its main objective is to present the reader with context to the research and analysis that is a result of the work presented in our thesis.

\section{Dependency Grammar}
The early roots of dependency grammar can possibly be traced back to P\={a}\d{n}ini's grammar of Sanskrit written in approximately 350/250 BC \cite{Kruijff:02}. However, the modern study of  dependency grammar is first presented in the works of \citeauthor{Tes:15}. In his work \textit{Elements of Structural Syntax}, \citeauthor{Tes:15} presents a theory of syntax by focusing on what he calls a \textit{connection} and \textit{dependency}:

\begin{displayquote}
The sentence is an \textit{organized whole}; its constituent parts are the \textit{words}. Every word that functions as part of a sentence is no longer isolated as in the dictionary: the mind perceives \textit{connections} between the word and its neighbors; the totality of these connections forms the scaffolding of the sentence. The structural connections establish relations of \textit{dependency} among the words. Each such connection in principle links a \textit{superior} term and an \textit{inferior} term. The superior term receives the name \textit{governor (r\'{e}gissant)}; the inferior term receives the name \textit{dependent (subordonn\'{e})}. \cite{Tes:15}.
\end{displayquote}

It is these \textit{connections}, according to \citeauthor{Tes:15}, that make a sentence meaningful: \say{[W]ithout them the sentence would not be intelligible} \cite{Tes:15}. From the works of \citeauthor{Tes:15}, the field of dependency grammar has grown into a wide range of traditions that have explored the notion of \textit{dependency} from a variety of different perspectives. Among these are the Prague School's Functional Generative Description, Meaning-Text Theory, and Hudson's Word Grammar \cite{Sgall:86, Mel:88, Hudson:90}. We will not give a detailed exposition on the differences and similarities between the various approaches to dependency grammar, but rather focus on the aspects that are informative as a precursor to our section on dependency parsing. What follows is a concise and formal definition of dependency grammar and a set of criteria that can be used for determining the connections between the words in a sentence.

\subsection{A formal description}
A \textit{dependency} can be described as a binary asymmetrical relation between the lexical units of a sentence, i.e. an arrow pointing from one word to another. Formally, we describe the dependencies in a sentence $\vec{w} = w_1 ... w_n$ as a directed graph on the set of positions $\vec{w}$ that contain an edge $i \rightarrow j$ if and only if $w_j$ depends on $w_i$ \cite{Kuhl:10}. A directed graph is used so as to represent a dependency going from one word to another. We can think of this as an arrow from one word to another. The common terms used in the research literature for the lexical unit that the arrow starts from is \textit{head}, and the one that is pointed to as \textit{dependent}. 

In addition there can be a \textit{label} added to the \textit{dependency} defining the type of connection that exists between a head and a dependent. There is no unified set of labels for dependency parsing, and a wide variety of different schemes exist in accordance with an underlying theoretical framework. Examining the dependency graph in figure \ref{dep1} we can visualise the formal description thus far: we have a lexical element that is the \textit{root} of the sentence, the verb "brought", and several \textit{labeled dependencies} between a \textit{head} and a \textit{dependent}. An example is the connection made between the verb "brought" and the noun "Bob", with the verb being the \textit{head} and the noun being the \textit{dependent}, with a \textit{labeled dependency} of type "nsubj".

\begin{figure}
    \begin{dependency}[]
        \begin{deptext}[column sep=1em, row sep=.1ex]
            Bob \& brought \& the \& cake \& to \& Alice \& . \\
        \end{deptext}
        \deproot{2}{Root}
        \depedge{2}{1}{nsubj}
        \depedge{2}{4}{obj}
        \depedge{4}{3}{det}
        \depedge{2}{5}{prep}
        \depedge{5}{6}{pobj}
        \depedge[edge unit distance=2ex]{2}{7}{punct}
    \end{dependency}
    \caption{An example of a dependency graph with labeled edgess.}
    \label{dep1}
\end{figure}

The criteria for establishing \textit{dependencies}, and defining which lexical unit should be head and dependent is of central concern to dependency grammar. In the case where the \textit{dependencies} have labels, the type of labels are determined by their own set of criteria. We can examine a set of criteria set forth by such grammarians as \citeauthor{Zwicky:85} and \citeauthor{Hudson:90} for determining the head \textit{H} and dependent \textit{D} in a construct \textit{C}:

\begin{enumerate}
\item (H) determines the syntactic category of (C) and can often replace (C).
\item (H) determines the semantic category of (C), whereas (D) specifies the semantic category of (C).
\item There must be a (H), whereas (D) is optional.
\item (H) selects the category of (D) and whether it is obligatory or optional.
\item The form of (D), whether it is agreement or government, depends on (H).
\item The linear position of (D) is specified with reference to (H).
\end{enumerate}

Different traditions of dependency grammar diverge in the interpretation and use of a set of criteria for identifying \textit{dependencies}. The list above encompass a set of syntactic and semantic criteria for establishing \textit{dependencies}, but do not fully cover the range of criteria that can be used to determine what can constitute as such.


\section{Dependency Parsing}
\subsection{Grammar-Driven Dependency Parsing}
\subsection{Data-Driven Dependency Parsing}


\section{Syntactic Dependency Parsing}


\section{Semantic Dependency Parsing}





