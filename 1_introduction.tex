\chapter{Introduction}
\label{chap:introduction}

Semantic dependency parsing is a Natural Language Processing (NLP) task that aims at producing meaning representations at the sentence-level. We can state the aims of semantic dependency parsing as a way of expressing predicate-argument relations in order to answer the question of \textit{Who did What to Whom?} In this regard there is certainly an overlap between semantic dependency parsing  and \textit{semantic role labeling} (SRL). 

The task of SRL is concerned with detecting the arguments of a predicate in a given sentence. Semantic dependency parsing usually has a broader scope than argument detection. In addition to the goals of SRL, semantic dependency parsing attempts to identify various semantic phenomena, such as negation, topicalization, relative clauses, and other scopal dependencies that are not part of the scope of SRL.

Examining the research community and the publications in the field of dependency parsing, we can see a growing interest in semantic dependency parsing in recent years. This can be attributed to both the advances made in the accuracy of state-of-the-art parsers, but also due to the successful application of such parsers and their representations in a wide range of computational tasks such as Information Extraction, Textual Inference, Machine Translation, Semantic Search, and Sentiment Analysis. A set of so-called shared tasks on semantic dependency parsing, which we will present in this thesis, have also stimulated the research community towards more research on this specific type of dependency parsing.

In this thesis we present our contribution to the field of semantic dependency parsing by doing a high-level contrastive error analysis of various state-of-the-art semantic dependency parsing systems. We will closely examine their results, and compare them in order to gain insights into the areas with the potential of improvements in parsing accuracy. We will show that the error analysis provided us with the grounds for examining the so-called frames, also referred to as sense distinctions, in order to make an attempt at improving previous results. Based on this analysis we build our own pipeline for classifying semantic frames. These frames are added as an extra layer to the graph annotations of semantic dependencies. So in this sense they are not part of the semantic dependency graph itself, but acts as additional semantic information. The classification of the frames themselves rely on the semantic dependency graph as features for training the classifier.

\section{Overview} 

% Background
\paragraph{Chapter 2} provides a background for our thesis. In this chapter we briefly outline dependency grammar, and then examine various approaches to dependency based parsing. We differentiate between grammar- and data-driven dependency parsing, and formally describe both of these approaches to dependency parsing. We divide data-driven dependency parsing in two main classes: transition-based and graph-based models. We examine these two models and give examples of their implementation by presenting a few examples of tools that are openly available. Finally, we define semantic dependency parsing, and show how this approach differentiates from syntactic dependency parsing. We will also argue why we should focus on semantic dependency parsing, and provide arguments for the reasoning behind writing this thesis.

\paragraph{Chapter 3} examines a few selected state-of-the-art semantic dependency parsers. We have chosen to focus on a set of data-driven parsers that where part of the Task 18 at SemEval 2015 on \textit{Broad-Coverage Semantic Dependency Parsing} (SemEval-2015) \cite{Oepen:15}. We present the parsing systems that where part of this task, and provide the reader with a background to the technology that drives them. We will also examine the target representations used for training and testing. Here we also examine Task 8 at SemEval 2014 (SemEval-2014) (see \citeA{Oepen:14}, in order to provide the reader with more background to SemEval 2015, and the changes from one year to the next.

\paragraph{Chapter 4} builds on the previous chapter by examining the results submitted by a set of parsing systems to SemEval-2015. By way of an in-depth contrastive error analysis of a set of state-of-the-art parsers we gain insights into some common errors that these parsers share. We examine four factors of semantic dependency parsing: (1) length factors, (2) graph factors, and (3) linguistic factors and (4) frames accuracy. The insights from this chapter lay the empirical foundation for our classification task.

\paragraph{Chapter 5} examines our own pipeline for classifying semantic frames. The analysis in Chapter \ref{chap:semantic} is used as basis for the type of classification performed in this chapter. In this chapter present our results and examine possible ways of improving the accuracy of our pipeline.

\paragraph{Chapter 6} is a summary and conclusion of our thesis. Here we give a short overview of what we have achieved in our thesis, and discuss how this relates to the research on semantic dependency parsing at large. We also discuss the possibilities for future work that might benefit from the analysis and classification task performed in our thesis.