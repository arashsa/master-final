\chapter{Introduction}
\label{chap:introduction}

Semantic dependency parsing is a Natural Language Processing (NLP) task that aims at producing meaning representations at the sentence-level. We can state the aims of semantic dependency parsing as a way of expressing predicate-argument relations in order to answer the question of \textit{Who did What to Whom?}. In this regard there is certainly an overlap between semantic dependency parsing  and \textit{semantic role labeling} (SRL). 

The task of SRL is concerned with detecting the arguments of a predicate in a given sentence. Semantic dependency parsing usually has a broader scope than argument detection. In addition to the goals of SRL, semantic dependency parsing attempts to identify various semantic phenomena, such as negation, and other scopal dependencies that are not part of the scope of SRL.

Examining the research community and the publications on the field, we can see a growing interest in semantic dependency parsing in recent years. This can be attributed to both the advances that has been made in the accuracy of state-of-the-art parsers, but also due to the successful application of such parsers and their representations in a wide range of computational tasks such as Information Extraction, Textual Inference, Machine Translation, Semantic Search, and Sentiment Analysis. A set of so-called shared tasks on semantic dependency parsing, which we will present in this thesis, have also stimulated the research community towards more research on this field.

In this thesis we present our contribution to the field of semantic dependency parsing by doing a high-level contrastive error analysis of various state-of-the-art semantic dependency parsing systems. We will closely examine their results, and compare them in order to gain insights into areas that can potentially gain in accuracy. We will also build our own pipeline for classifying semantic frames, also referred to as sense distinctions. The frames are added as an extra layer to the graph annotations of semantic dependencies. So in this sense they are not part of the semantic dependency graph itself, but acts as additional semantic information. Instead, the classification of the frames themselves rely on the semantic dependency graph as part of its classification task. We build upon previous research on classifying frames, and use the openly available scikit-learn framework for building a classifier. 

\section{Overview} 

% Background
\paragraph{Chapter 2} provides a background for our thesis. In this chapter we briefly outline dependency grammar, and then examine various approaches to dependency based parsing. We differentiate between grammar- and data-driven dependency parsing, and formally describe both of these approaches to dependency parsing. We divide data-driven dependency parsing in two main classes: transition-based and graph-based models. We examine these two models and give examples of their implementation by presenting a few examples of tools that are openly available. Finally, we define semantic dependency parsing, and show how this approach differentiates from syntactic dependency parsing. We will also argue why we should focus on semantic dependency parsing, and provide arguments for the reasoning behind writing this thesis.

\paragraph{Chapter 3} examines a few selected state-of-the-art semantic dependency parsers. We have chosen to focus on a set of data-driven parsers that where part of the Task 18 at SemEval 2015 on \textit{Broad-Coverage Semantic Dependency Parsing} (SDP) \cite{Oepen:15}. We present the parsing systems that where part of this task, and provide the reader with a background to the technology that drives them. We will also examine the target representations used for training and testing. Here we also examine Task 8 at SemEval 2014 (see \citeA{Oepen:14}, in order to provide the reader with more background to SemEval 2015, and the changes from one year to the next.

\paragraph{Chapter 4} builds on the previous chapter by examining the results of the semantic dependency parsers presented there. By way of an in-depth contrastive error analysis of a set of state-of-the-art parsers we gain insights into some common errors that these parsers share, and examine if there is common ground or differences to the errors they might produce. With this insight we build the knowledge and foundation necessary for our classification task in the next chapter. 

\paragraph{Chapter 5} examines our own pipeline for classifying semantic frames. We use the presentation in Chapter \ref{chap:semantic} and analysis in Chapter \ref{chap:analysis} as basis for building our pipeline. We will present our results and examines possible ways of improving the accuracy of our pipeline.

\paragraph{Chapter 6} is a summary and conclusion of our thesis. Here we give a short overview of what we have achieved in our thesis, and discuss how this relates to the research on semantic dependency parsing at large. We also discuss the possibilities for future work that might benefit from the analysis and classification task of our thesis.