\chapter{Introduction}
\label{chap:introduction}

% Motivere hva som er resultatet, hva har jeg gjort, og hvem som trenger det, hvilken spørsmål har du stilt.
% Lingvistiske trekk som vi ser på, både i analysen og eksperimenter.

Semantic dependency parsing is a Natural Language Processing (NLP) task that aims at producing meaning representations at the sentence level. Its outcome is to express predicate-argument relations in order to answer the question of \textit{Who did What to Whom?} In this regard there is an overlap between semantic dependency parsing and \textit{semantic role labeling} (SRL). 

The task of SRL is concerned with detecting the arguments of a predicate in a given sentence, and is often limited to only verbal predicates. Semantic dependency parsing has a broader scope than argument detection. In addition to the goals of SRL, semantic dependency parsing attempts to identify various semantic phenomena, such as negation, topicalization, relative clauses, and other scopal dependencies that are usually left out in SRL.

An examination of recent research and publications in the field of dependency parsing shows a growing interest in the semantic aspect of dependency parsing. This increasing popularity stems both from advances made in the accuracy of state-of-the-art parsers, successful applications of such parsers and their representations in a wide range of computational tasks, such as Information Extraction, Textual Inference, Machine Translation, Semantic Search, and Sentiment Analysis. A set of so-called \textit{shared tasks} on semantic dependency parsing, which we will present in this thesis, have also stimulated the research community towards more research on this specific type of dependency parsing.

An second focus of this thesis is \textit{semantic frame} classification. A semantic frame is intricately linked to the \textit{sense distinctions} of a word, i.e. how a singular term and its arguments are to be interpreted. This task is related to the NLP task of word sense disambiguation, where different sets of classes are used in order to differentiate words into classes of meaning representation. Where semantic dependency parsing adds a layer of semantics to a sentence by adding connections between words, semantic frames adds a layer by adding several interpretations to individual words.

This thesis aims to contribute to the field of semantic dependency parsing and frame classification by performing a high-level contrastive error analysis of various state-of-the-art semantic dependency parsing systems. The analysis will consist of a close examination and comparison of these systems, which will provide insight to, and serve as an empirical foundation and basis for our own research. The area that we found most promising as a focal point for our own research proved to be semantic frame classification.

In order to build a state-of-the-art semantic frame classifier, we will, firstly, examine a set of machine learning algorithms, and secondly, perform an in-depth feature selection based on available data sets for semantic frame classification. We hope to demonstrate that the results of our classifier can be used as a basis for improving the accuracy of current semantic dependency parsers by improving their frame classification accuracy.

\section{Overview} 

% Background
\paragraph{Chapter 2} provides background for our thesis. In this chapter we briefly outline dependency grammar, and examine various approaches to dependency based parsing. We differentiate between grammar- and data-driven dependency parsing, and formally describe both of these approaches. We divide data-driven dependency parsing in two main classes: transition-based and graph-based models. We examine these two models and give examples of their implementation. Finally, we define semantic dependency parsing, and demonstrate how this approach differs from syntactic dependency parsing.

\paragraph{Chapter 3} examines a few selected state-of-the-art semantic dependency parsing systems. We have chosen to focus on a set of data-driven parsers that participated in Task 18 at SemEval 2015 on \textit{Broad-Coverage Semantic Dependency Parsing} (SemEval-2015) \cite{Oepen:15}. We present the parsing systems that where part of this task, and provide the reader with their technical details. We will also examine the target representations used for training and testing that were part of SemEval-2015. Here we also examine Task 8 at SemEval 2014 (see \citeA{Oepen:14}), which was the predecessor to SemEval-2015.

\paragraph{Chapter 4} builds on the previous chapter by examining the results submitted by a subset of the parsing systems participating in SemEval-2015. We perform an in-depth contrastive error analysis of the parsing systems in order to gain insights into common errors shared by these systems. We examine four factors of semantic dependency parsing: (1) length factors, (2) graph factors, (3) linguistic factors and (4) frames accuracy. The insights from this analysis will be the empirical foundation for our experiments.

\paragraph{Chapter 5} presents the experimental setup we use as basis for our semantic frame classification task. We present the data sets used for training, development and testing. We then present the type of features that we will focus on in our experiments, and the reasoning behind the feature selection. Lastly we present a description of the machine learning algorithms we employ in our experiments.

% Our experiments will rely on a selection of machine learning algorithms, for which we provide high-level descriptions of each.

% examines our own pipeline for classifying semantic frames. The analysis in Chapter \ref{chap:semantic} led us in choosing semantic frames as the focal point of our own work. In this chapter we build a pipeline for classifying semantic frames by examining a set of machine learning algorithms. We start off by presenting a baseline accuracy, and see if we can improve upon this baseline by fine tuning the machine learning algorithms, and by way of exploring a set of features used for training. We show that by using a wide range of features for our classifier, we can achieve state-of-the-art results in predicting semantic frames.

\paragraph{Chapter 6} presents the results of our experiments. We start the chapter by establishing a baseline score for semantic frame classification that we use as the comparative basis for evaluating the effects of our feature selection. We then present the results of each set of features and their impact on the overall accuracy of our classifier. In our final experiments we show that we can achieve state-of-the-art accuracy using an experimental approach where a large feature space is explored. We show that the results of our semantic frame classifier can be used in conjunction with the highest scoring semantic dependency parsers participating in SemEval-2015. We demonstrate that we can increase these system's semantic frame classification accuracy. We thus conclude that our results have proved fruitful in pushing the state-of-art in semantic dependency parsing one small step forward.

% is a summary and conclusion of our thesis. Here we give a short overview of what we have achieved in our thesis, and discuss how this relates to the research on semantic dependency parsing at large. We also discuss the possibilities for future work that might benefit from the analysis and classification task performed in our thesis.

\paragraph{Chapter 7} functions as concluding remarks to our thesis. We summarize our main contributions, and discuss possible future work.